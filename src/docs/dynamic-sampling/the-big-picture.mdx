---
title: The Big Picture
sidebar_order: 1
---

The lifecycle of an event in Sentry is a complex process which involves many components. Dynamic Sampling is one of these components, and it is important to understand how it fits into the bigger picture.

![Sequencing](/images/sequencing.png)

## Sequencing

Dynamic Sampling occurs at the edge of our ingestion pipeline, precisely in [Relay](https://github.com/getsentry/relay).

When transaction events arrive, in a simplified model, they go through the following steps:

1. **Inbound data filters**: every transaction runs through inbound data filters as configured in project settings, such as legacy browsers or denied releases. Transactions dropped here do not count for quota and are not included in ‚Äútotal transactions‚Äù data.
2. **Quota enforcement**: Sentry charges for all further transactions sent in, before events are passed on to dynamic sampling.
3. **Metrics extraction**: after passing quotas, Sentry extracts metrics from transactions. These metrics show up in the product as ‚Äútotal transactions‚Äù and provide granular numbers for the performance and frequency of every application transaction.
4. **Dynamic Sampling**: based on an internal set of rules, Relay determines a sample rate for every incoming transaction event. A random number generator finally decides whether this payload should be indexed or dropped.
5. **Rate limiting**: transactions that are sampled by dynamic sampling (i.e. not dropped) will be stored and indexed. To protect the infrastructure, internal rate limits apply at this point. Under normal operation, this **rate limit is never reached** since dynamic sampling already reduces the volume of indexed events.

<Alert title="üí° Example" level="info">

A customer is sending 1000 transactions per second to Sentry:
1. 100 transactions per second are from old browsers and get dropped through an inbound data filter.
2. Since the customer is a high roller, they have plenty of quota, so the remaining 900 transactions per second show up as total transactions in the product.
3. Their current overall dynamic sample rate is at 20%, which statistically samples 180 transactions per second.
4. Since this is above the 100/s limit, about 80 transactions per second are randomly dropped, and the rest is stored.

</Alert>

## Rate Limiting and Total Transactions

The ingestion pipeline has two kinds of rate limits that  behave differently compared to organizations without dynamic sampling:

1. **High-level request limits on load balancers**: they do not differentiate which data is sent by clients and drop requests as soon as the throughput from clients reaches the limit.
2. **Specific limits per data category in Relay**: this applies once requests have been parsed and have gone through basic handling (see [Sequencing](#sequencing) above).

## Client Side Sampling and Dynamic Sampling

Clients have their own [traces sample rate](https://docs.sentry.io/platforms/javascript/performance/#configure-the-sample-rate). While documentation will generally suggest a sample rate of `1.0` (100%), especially large backend applications may need to lower this sample rate to reduce overheads introduced by the SDK. The client sample rate controls how many transactions arrive at Sentry, which is also what the customer is charged.

![Client and Dynamic Sampling](/images/clientAndDynamicSampling.png)

Dynamic sampling further reduces how many transactions get indexed internally. **While many-to-most graphs and numbers in the product are based on total transactions**, accessing spans and tags requires indexed transactions. The sample rates apply on top of each other.

## Total Transactions

To collect unsampled information for ‚Äútotal‚Äù transactions in the Performance product and Discover, Relay extracts [metrics](https://getsentry.github.io/relay/relay_metrics/index.html) from transactions. In short, these metrics comprise:

- Counts and durations for all transactions.
- A distribution (histogram) for every web vital.
- The number of unique users (set).

Each of these metrics can be filtered and grouped by `release`, `environment`, and `transaction` name.

For more granular queries, **indexed transaction events are needed**. _The purpose of dynamic sampling here is to ensure that enough representatives are always available to satisfy product workflows._

<Alert title="üí° Example" level="info">

If Sentry applies a 1% dynamic sample rate, you can still receive accurate TPM (transactions per minute) and web vital quantiles through total transaction data backed by metrics. There is also a listing of each of these numbers by the transaction.

When you go into transaction summary or Discover, you might want to now split the data by operating system or a custom tag you‚Äôve added to your transactions. This granularity is not offered by metrics, so **these queries need to use indexed transactions**.

</Alert>
